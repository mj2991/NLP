{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "[nltk_data] Downloading package stopwords to\n",
      "[nltk_data]     /Users/mujahidabdullahi/nltk_data...\n",
      "[nltk_data]   Package stopwords is already up-to-date!\n"
     ]
    }
   ],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import random\n",
    "from sklearn.datasets import fetch_20newsgroups\n",
    "from sklearn import decomposition\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from scipy import linalg\n",
    "import matplotlib.pyplot as pltb\n",
    "from sklearn.feature_extraction.text import CountVectorizer, TfidfVectorizer\n",
    "import nltk\n",
    "from nltk.corpus import stopwords\n",
    "import re\n",
    "\n",
    "nltk.download('stopwords')\n",
    "stopwords = stopwords.words('english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>id</th>\n",
       "      <th>comment_text</th>\n",
       "      <th>toxic</th>\n",
       "      <th>severe_toxic</th>\n",
       "      <th>obscene</th>\n",
       "      <th>threat</th>\n",
       "      <th>insult</th>\n",
       "      <th>identity_hate</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>000103f0d9cfb60f</td>\n",
       "      <td>D'aww! He matches this background colour I'm s...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>000113f07ec002fd</td>\n",
       "      <td>Hey man, I'm really not trying to edit war. It...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>0001b41b1c6bb37e</td>\n",
       "      <td>\"\\nMore\\nI can't make any real suggestions on ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>0001d958c54c6e35</td>\n",
       "      <td>You, sir, are my hero. Any chance you remember...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>00025465d4725e87</td>\n",
       "      <td>\"\\n\\nCongratulations from me as well, use the ...</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "      <td>0</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                 id                                       comment_text  toxic  \\\n",
       "1  000103f0d9cfb60f  D'aww! He matches this background colour I'm s...      0   \n",
       "2  000113f07ec002fd  Hey man, I'm really not trying to edit war. It...      0   \n",
       "3  0001b41b1c6bb37e  \"\\nMore\\nI can't make any real suggestions on ...      0   \n",
       "4  0001d958c54c6e35  You, sir, are my hero. Any chance you remember...      0   \n",
       "5  00025465d4725e87  \"\\n\\nCongratulations from me as well, use the ...      0   \n",
       "\n",
       "   severe_toxic  obscene  threat  insult  identity_hate  \n",
       "1             0        0       0       0              0  \n",
       "2             0        0       0       0              0  \n",
       "3             0        0       0       0              0  \n",
       "4             0        0       0       0              0  \n",
       "5             0        0       0       0              0  "
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df = pd.read_csv('train.csv')\n",
    "test_df = pd.read_csv('test.csv')\n",
    "train_df_sample = train_df.iloc[1:100000,:]\n",
    "val_df = train_df.iloc[100000:-1,:]\n",
    "train_df_sample.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def add_non_toxic(*argv):\n",
    "    if sum(argv) > 0:\n",
    "        val = 0\n",
    "    else:\n",
    "        val = 1\n",
    "    return(val)   "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def prep_data(df):\n",
    "    df['non_toxic'] = df.apply(lambda df: add_non_toxic(\n",
    "    df['toxic'], df['severe_toxic'],df['obscene'], df['threat'], df['insult'], df['insult']), axis = 1)\n",
    "    df = pd.melt(df, id_vars = ['id', 'comment_text'], value_vars = ['toxic', 'severe_toxic', 'obscene', \n",
    "                             'threat', 'insult', 'identity_hate', 'non_toxic'])\n",
    "    df = df[df['value'] == 1].drop(['value'], axis = 1)\n",
    "    df.rename({'variable':'label'}, axis = 1, inplace = True)\n",
    "    \n",
    "    return(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:3: SettingWithCopyWarning: \n",
      "A value is trying to be set on a copy of a slice from a DataFrame.\n",
      "Try using .loc[row_indexer,col_indexer] = value instead\n",
      "\n",
      "See the caveats in the documentation: http://pandas.pydata.org/pandas-docs/stable/indexing.html#indexing-view-versus-copy\n",
      "  This is separate from the ipykernel package so we can avoid doing imports until\n"
     ]
    }
   ],
   "source": [
    "train_df, val_df= [prep_data(df) for df in [train_df, val_df]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df_comments = train_df['comment_text'].tolist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = train_df['comment_text'][train_df['label'] == 'toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "15294"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(toxic_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "COCKSUCKER BEFORE YOU PISS AROUND ON MY WORK\n",
      "Hey... what is it..\n",
      "@ | talk .\n",
      "What is it... an exclusive group of some WP TALIBANS...who are good at destroying, self-appointed purist who GANG UP any one who asks them questions abt their ANTI-SOCIAL and DESTRUCTIVE (non)-contribution at WP?\n",
      "\n",
      "Ask Sityush to clean up his behavior than issue me nonsensical warnings...\n",
      "Bye! \n",
      "\n",
      "Don't look, come or think of comming back! Tosser.\n",
      "You are gay or antisemmitian? \n",
      "\n",
      "Archangel WHite Tiger\n",
      "\n",
      "Meow! Greetingshhh!\n",
      "\n",
      "Uh, there are two ways, why you do erased my comment about WW2, that holocaust was brutally slaying of Jews and not gays/Gypsys/Slavs/anyone...\n",
      "\n",
      "1 - If you are anti-semitian, than shave your head bald and go to the skinhead meetings!\n",
      "\n",
      "2 - If you doubt words of the Bible, that homosexuality is a deadly sin, make a pentagram tatoo on your forehead go to the satanistic masses with your gay pals!\n",
      "\n",
      "3 - First and last warning, you fucking gay - I won't appreciate if any more nazi shwain would write in my page! I don't wish to talk to you anymore!\n",
      "\n",
      "Beware of the Dark Side!\n",
      "FUCK YOUR FILTHY MOTHER IN THE ASS, DRY!\n",
      "I'm Sorry \n",
      "\n",
      "I'm sorry I screwed around with someones talk page.  It was very bad to do.  I know how having the templates on their talk page helps you assert your dominance over them.  I know I should bow down to the almighty administrators.  But then again, I'm going to go play outside....with your mom.   76.122.79.82\n",
      "GET FUCKED UP. GET FUCKEEED UP.  GOT A DRINK THAT YOU CANT PUT DOWN???/ GET FUCK UP GET FUCKED UP.  I'M FUCKED UP RIGHT NOW!\n",
      "Stupid peace of shit stop deleting my stuff asshole go die and fall in a hole go to hell!\n",
      "=Tony Sidaway is obviously a fistfuckee. He loves an arm up his ass.\n",
      "My Band Page's deletion. You thought I was gone. \n",
      "\n",
      "Deleting the comment I posted on your 'talk page' does not delete my feelings for your hasty decision to delete my page. You, sir, are still a cock-sucking douche fuck. Sit back for a second and think about what your life has become. ............ Done? That didn't take long did it? Nope. Because, as I am most certainly aware, your life is a shitstorm of sitting in front of the computer masturbating to fictional creatures. Your attempts to get rid of me are mediocre at best. You are constantly sucking the dick of failure. You don't want a personal attack, huh? Well, too bad, Fuckcock McDickerson. You've got one. From me. You can go ahead and delete my profile from wikipedia. I'll just make another one and come right back to 'Syrthiss's talk page and insult the dick off of you. How could you shatter the dreams of an innocent eighteen year old college freshman trying to make a name for his band. Does that make you happy? Fucking with people because you're an overweight, single, old man in a dead-end job. Did you spot that perhaps someone else was going to follow his dreams and you were trying to hold him back so somebody else could suffer like you? Yes you did. I don't make empty threats, so I won't be saying anything along the lines of 'i'll hurt you' or 'i'll eat the children from within your sister's womb', but I will say that you are a asshole, son-of-a-bitch, mother fucking cock sucker. So, go eat some more food and drown your sorrows you premature ejaculating, bald headed fuck.\n",
      "\n",
      "You should do something nice for yourself, maybe go grab a couple of Horny Goat Weeds from your local convenience store and jack off for a little longer than three minutes tonight.\n",
      "\n",
      "Sincerely,\n",
      "An Asshole That's Better Than You In Every Way.\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(toxic_comments[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "non_toxic_comments = train_df.comment_text[train_df['label'] == 'non_toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "143400"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(non_toxic_comments)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Explanation\n",
      "Why the edits made under my username Hardcore Metallica Fan were reverted? They weren't vandalisms, just closure on some GAs after I voted at New York Dolls FAC. And please don't remove the template from the talk page since I'm retired now.89.205.38.27\n",
      "D'aww! He matches this background colour I'm seemingly stuck with. Thanks.  (talk) 21:51, January 11, 2016 (UTC)\n",
      "Hey man, I'm really not trying to edit war. It's just that this guy is constantly removing relevant information and talking to me through edits instead of my talk page. He seems to care more about the formatting than the actual info.\n",
      "\"\n",
      "More\n",
      "I can't make any real suggestions on improvement - I wondered if the section statistics should be later on, or a subsection of \"\"types of accidents\"\"  -I think the references may need tidying so that they are all in the exact same format ie date format etc. I can do that later on, if no-one else does first - if you have any preferences for formatting style on references or want to do it yourself please let me know.\n",
      "\n",
      "There appears to be a backlog on articles for review so I guess there may be a delay until a reviewer turns up. It's listed in the relevant form eg Wikipedia:Good_article_nominations#Transport  \"\n",
      "You, sir, are my hero. Any chance you remember what page that's on?\n",
      "\"\n",
      "\n",
      "Congratulations from me as well, use the tools well.  · talk \"\n",
      "Your vandalism to the Matt Shirvington article has been reverted.  Please don't do it again, or you will be banned.\n",
      "Sorry if the word 'nonsense' was offensive to you. Anyway, I'm not intending to write anything in the article(wow they would jump on me for vandalism), I'm merely requesting that it be more encyclopedic so one can use it for school as a reference. I have been to the selective breeding page but it's almost a stub. It points to 'animal breeding' which is a short messy article that gives you no info. There must be someone around with expertise in eugenics? 93.161.107.169\n",
      "alignment on this subject and which are contrary to those of DuLithgow\n",
      "\"\n",
      "Fair use rationale for Image:Wonju.jpg\n",
      "\n",
      "Thanks for uploading Image:Wonju.jpg. I notice the image page specifies that the image is being used under fair use but there is no explanation or rationale as to why its use in Wikipedia articles constitutes fair use. In addition to the boilerplate fair use template, you must also write out on the image description page a specific explanation or rationale for why using this image in each article is consistent with fair use.\n",
      "\n",
      "Please go to the image description page and edit it to include a fair use rationale.\n",
      "\n",
      "If you have uploaded other fair use media, consider checking that you have specified the fair use rationale on those pages too. You can find a list of 'image' pages you have edited by clicking on the \"\"my contributions\"\" link (it is located at the very top of any Wikipedia page when you are logged in), and then selecting \"\"Image\"\" from the dropdown box. Note that any fair use images uploaded after 4 May, 2006, and lacking such an explanation will be deleted one week after they have been uploaded, as described on criteria for speedy deletion. If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • ) \n",
      "Unspecified source for Image:Wonju.jpg\n",
      "\n",
      "Thanks for uploading Image:Wonju.jpg. I noticed that the file's description page currently doesn't specify who created the content, so the copyright status is unclear. If you did not create this file yourself, then you will need to specify the owner of the copyright. If you obtained it from a website, then a link to the website from which it was taken, together with a restatement of that website's terms of use of its content, is usually sufficient information. However, if the copyright holder is different from the website's publisher, then their copyright should also be acknowledged.\n",
      "\n",
      "As well as adding the source, please add a proper copyright licensing tag if the file doesn't have one already. If you created/took the picture, audio, or video then the  tag can be used to release it under the GFDL. If you believe the media meets the criteria at Wikipedia:Fair use, use a tag such as  or one of the other tags listed at Wikipedia:Image copyright tags#Fair use. See Wikipedia:Image copyright tags for the full list of copyright tags that you can use.\n",
      "\n",
      "If you have uploaded other files, consider checking that you have specified their source and tagged them, too. You can find a list of files you have uploaded by following [ this link]. Unsourced and untagged images may be deleted one week after they have been tagged, as described on criteria for speedy deletion. If the image is copyrighted under a non-free license (per Wikipedia:Fair use) then the image will be deleted 48 hours after . If you have any questions please ask them at the Media copyright questions page. Thank you. (talk • contribs • ) \"\n"
     ]
    }
   ],
   "source": [
    "print(\"\\n\".join(non_toxic_comments[:10]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "vectorizer = CountVectorizer(stop_words='english')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_doc_matrix = vectorizer.fit_transform(train_df_comments).todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [],
   "source": [
    "vocab = np.array(vectorizer.get_feature_names())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "189460 (178498, 189460)\n"
     ]
    }
   ],
   "source": [
    "print(len(vocab), word_doc_matrix.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array(['aagadu', 'aage', 'aagf', 'aagin', 'aah', 'aahahahahahaha',\n",
       "       'aahank', 'aahh', 'aahil', 'aahoa'], dtype='<U4955')"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "vocab[10000:10010]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "##u, s, v = np.linalg.svd(word_doc_matrix, full_matrices = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['i',\n",
       " 'me',\n",
       " 'my',\n",
       " 'myself',\n",
       " 'we',\n",
       " 'our',\n",
       " 'ours',\n",
       " 'ourselves',\n",
       " 'you',\n",
       " \"you're\",\n",
       " \"you've\",\n",
       " \"you'll\",\n",
       " \"you'd\",\n",
       " 'your',\n",
       " 'yours',\n",
       " 'yourself',\n",
       " 'yourselves',\n",
       " 'he',\n",
       " 'him',\n",
       " 'his',\n",
       " 'himself',\n",
       " 'she',\n",
       " \"she's\",\n",
       " 'her',\n",
       " 'hers',\n",
       " 'herself',\n",
       " 'it',\n",
       " \"it's\",\n",
       " 'its',\n",
       " 'itself',\n",
       " 'they',\n",
       " 'them',\n",
       " 'their',\n",
       " 'theirs',\n",
       " 'themselves',\n",
       " 'what',\n",
       " 'which',\n",
       " 'who',\n",
       " 'whom',\n",
       " 'this',\n",
       " 'that',\n",
       " \"that'll\",\n",
       " 'these',\n",
       " 'those',\n",
       " 'am',\n",
       " 'is',\n",
       " 'are',\n",
       " 'was',\n",
       " 'were',\n",
       " 'be',\n",
       " 'been',\n",
       " 'being',\n",
       " 'have',\n",
       " 'has',\n",
       " 'had',\n",
       " 'having',\n",
       " 'do',\n",
       " 'does',\n",
       " 'did',\n",
       " 'doing',\n",
       " 'a',\n",
       " 'an',\n",
       " 'the',\n",
       " 'and',\n",
       " 'but',\n",
       " 'if',\n",
       " 'or',\n",
       " 'because',\n",
       " 'as',\n",
       " 'until',\n",
       " 'while',\n",
       " 'of',\n",
       " 'at',\n",
       " 'by',\n",
       " 'for',\n",
       " 'with',\n",
       " 'about',\n",
       " 'against',\n",
       " 'between',\n",
       " 'into',\n",
       " 'through',\n",
       " 'during',\n",
       " 'before',\n",
       " 'after',\n",
       " 'above',\n",
       " 'below',\n",
       " 'to',\n",
       " 'from',\n",
       " 'up',\n",
       " 'down',\n",
       " 'in',\n",
       " 'out',\n",
       " 'on',\n",
       " 'off',\n",
       " 'over',\n",
       " 'under',\n",
       " 'again',\n",
       " 'further',\n",
       " 'then',\n",
       " 'once',\n",
       " 'here',\n",
       " 'there',\n",
       " 'when',\n",
       " 'where',\n",
       " 'why',\n",
       " 'how',\n",
       " 'all',\n",
       " 'any',\n",
       " 'both',\n",
       " 'each',\n",
       " 'few',\n",
       " 'more',\n",
       " 'most',\n",
       " 'other',\n",
       " 'some',\n",
       " 'such',\n",
       " 'no',\n",
       " 'nor',\n",
       " 'not',\n",
       " 'only',\n",
       " 'own',\n",
       " 'same',\n",
       " 'so',\n",
       " 'than',\n",
       " 'too',\n",
       " 'very',\n",
       " 's',\n",
       " 't',\n",
       " 'can',\n",
       " 'will',\n",
       " 'just',\n",
       " 'don',\n",
       " \"don't\",\n",
       " 'should',\n",
       " \"should've\",\n",
       " 'now',\n",
       " 'd',\n",
       " 'll',\n",
       " 'm',\n",
       " 'o',\n",
       " 're',\n",
       " 've',\n",
       " 'y',\n",
       " 'ain',\n",
       " 'aren',\n",
       " \"aren't\",\n",
       " 'couldn',\n",
       " \"couldn't\",\n",
       " 'didn',\n",
       " \"didn't\",\n",
       " 'doesn',\n",
       " \"doesn't\",\n",
       " 'hadn',\n",
       " \"hadn't\",\n",
       " 'hasn',\n",
       " \"hasn't\",\n",
       " 'haven',\n",
       " \"haven't\",\n",
       " 'isn',\n",
       " \"isn't\",\n",
       " 'ma',\n",
       " 'mightn',\n",
       " \"mightn't\",\n",
       " 'mustn',\n",
       " \"mustn't\",\n",
       " 'needn',\n",
       " \"needn't\",\n",
       " 'shan',\n",
       " \"shan't\",\n",
       " 'shouldn',\n",
       " \"shouldn't\",\n",
       " 'wasn',\n",
       " \"wasn't\",\n",
       " 'weren',\n",
       " \"weren't\",\n",
       " 'won',\n",
       " \"won't\",\n",
       " 'wouldn',\n",
       " \"wouldn't\"]"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {},
   "outputs": [],
   "source": [
    "def preprocess_text(df):\n",
    "    detokenized_doc = []\n",
    "    df['comment_text'] = df['comment_text'].str.replace(\"[^a-zA-Z]\", \" \")\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: x.split())\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: [item for item in x if item.lower() not in stopwords])\n",
    "    df['comment_text'] = df['comment_text'].apply(lambda x: ' '.join(x))\n",
    "    \n",
    "    return(df)                                                     "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_df, val_df, test_df = [preprocess_text(df) for df in [train_df, val_df, test_df]]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Using fast ai library"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai import *\n",
    "from fastai.text import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [],
   "source": [
    "path = '/Users/mujahidabdullahi/.fastai/data/toxic_comments_classification'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [],
   "source": [
    "toxic_comments = TextClasDataBunch.from_df(path, train_df=train_df, valid_df=val_df, test_df=test_df, label_cols=2,\n",
    "                                      text_cols=[\"comment_text\"], no_check=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "xxbos xxmaj hey xxmaj rama xxmaj hey xxmaj rama xxmaj xxunk whatever name keep nose business tend affairs want post message users xxmaj david xxmaj xxunk talk pages business stay toxic\n"
     ]
    }
   ],
   "source": [
    "print(toxic_comments.train_dl.x[1000], toxic_comments.train_dl.y[1000])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "60000 284532\n"
     ]
    }
   ],
   "source": [
    "print(len(toxic_comments.train_dl.vocab.itos), len(toxic_comments.train_dl.vocab.stoi))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['historians',\n",
       " 'industry',\n",
       " 'advance',\n",
       " 'base',\n",
       " 'tend',\n",
       " 'applies',\n",
       " 'push',\n",
       " 'philosophy',\n",
       " 'understood',\n",
       " 'uncivil',\n",
       " 'profile',\n",
       " 'wanna',\n",
       " 'mainly',\n",
       " 'activity',\n",
       " 'expanded',\n",
       " 'portal',\n",
       " 'hide',\n",
       " 'whoever',\n",
       " 'judge',\n",
       " 'draft']"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "toxic_comments.vocab.itos[2000:2020]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_term_doc_matrix(label_list, vocab_len):\n",
    "    j_indices = []\n",
    "    indptr = []\n",
    "    values = []\n",
    "    indptr.append(0)\n",
    "\n",
    "    for i, doc in enumerate(label_list):\n",
    "        feature_counter = Counter(doc.data)\n",
    "        j_indices.extend(feature_counter.keys())\n",
    "        values.extend(feature_counter.values())\n",
    "        indptr.append(len(j_indices))\n",
    "        \n",
    "#     return (values, j_indices, indptr)\n",
    "\n",
    "    return scipy.sparse.csr_matrix((values, j_indices, indptr),\n",
    "                                   shape=(len(indptr) - 1, vocab_len),\n",
    "                                   dtype=int)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_doc_train = get_term_doc_matrix(toxic_comments.train_dl.x, len(toxic_comments.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_doc_valid = get_term_doc_matrix(toxic_comments.valid_dl.x, len(toxic_comments.vocab.itos))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(178498, 60000) (66575, 60000)\n"
     ]
    }
   ],
   "source": [
    "print(word_doc_train.todense().shape, word_doc_valid.todense().shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [],
   "source": [
    "identity_hate = toxic_comments.train_dl.y.c2i['identity_hate']\n",
    "insult = toxic_comments.train_dl.y.c2i['insult']\n",
    "non_toxic = toxic_comments.train_dl.y.c2i['non_toxic']\n",
    "obscene = toxic_comments.train_dl.y.c2i['obscene']\n",
    "severe_toxic = toxic_comments.train_dl.y.c2i['severe_toxic']\n",
    "threat = toxic_comments.train_dl.y.c2i['threat']\n",
    "toxic = toxic_comments.train_dl.y.c2i['toxic']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/ipykernel_launcher.py:1: FutureWarning: elementwise comparison failed; returning scalar instead, but in the future will perform elementwise comparison\n",
      "  \"\"\"Entry point for launching an IPython kernel.\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "array([0, 0, 1, 0, ..., 0, 0, 0, 0], dtype=int64)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "np.squeeze(np.asarray(word_doc_train[toxic_comments.train_dl.y.items == \"identity_hate\"].sum(0)))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {},
   "outputs": [],
   "source": [
    "def probability(word_doc_matrix, category):\n",
    "    n_category = np.squeeze(np.asarray(word_doc_matrix[toxic_comments.train_dl.y.items == category].sum(0)))\n",
    "    p_category = (n_category + 1)/((toxic_comments.train_dl.y.items == category).sum() + 1)\n",
    "    return(p_category)  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_identity_hate, pr_insult, pr_non_toxic,pr_obscene,\\\n",
    "pr_severe_toxic, pr_threat, pr_toxic = [probability(word_doc_train, category) for \\\n",
    "                                                            category in [identity_hate, insult, non_toxic,obscene,\\\n",
    "                                                                         severe_toxic, threat, toxic]]                                                                                                                                                                                                                                                                                      "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_identity_hate, r_insult, r_non_toxic,r_obscene,\\\n",
    "r_severe_toxic, r_threat, r_toxic = [np.log(x/np.mean([pr_identity_hate, pr_insult, pr_non_toxic,pr_obscene, pr_severe_toxic, \\\n",
    "                                      pr_threat, pr_toxic])) for x in  [pr_identity_hate, pr_insult, pr_non_toxic, \\\n",
    "                                                                   pr_obscene,  pr_severe_toxic, pr_threat, pr_toxic]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_identity_hate, b_insult, b_non_toxic,b_obscene,\\\n",
    "b_severe_toxic, b_threat, b_toxic = [np.log(x.mean()/np.mean(np.mean([pr_identity_hate, pr_insult, pr_non_toxic,pr_obscene, pr_severe_toxic, \\\n",
    "                                      pr_threat, pr_toxic]))) for x in  [pr_identity_hate, pr_insult, pr_non_toxic, \\\n",
    "                                                                   pr_obscene,  pr_severe_toxic, pr_threat, pr_toxic]]\n",
    "    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "u\n",
      "wikipedia\n",
      "like\n",
      "fuck\n",
      "fucking\n",
      "xxup\n",
      "xxmaj\n",
      "xxbos\n",
      "xxunk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_insulting_words = np.argpartition(r_toxic, -10)[-10:]\n",
    "[print(k) for k in [toxic_comments.vocab.itos[i] for i in top_insulting_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "fucking\n",
      "faggot\n",
      "nigger\n",
      "gay\n",
      "fuck\n",
      "jew\n",
      "fat\n",
      "xxmaj\n",
      "xxbos\n",
      "xxup\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_identity_hate_words = np.argpartition(r_identity_hate, -10)[-10:]\n",
    "[print(k) for k in [toxic_comments.vocab.itos[i] for i in top_identity_hate_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "would\n",
      "please\n",
      "talk\n",
      "article\n",
      "wikipedia\n",
      "page\n",
      "xxup\n",
      "xxmaj\n",
      "xxbos\n",
      "xxunk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_non_toxic_words = np.argpartition(r_non_toxic, -10)[-10:]\n",
    "[print(k) for k in [toxic_comments.vocab.itos[i] for i in top_non_toxic_words]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(66575, 60000) (60000,)\n"
     ]
    }
   ],
   "source": [
    "print(word_doc_valid.shape, r_identity_hate.shape) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelyhood = [r_identity_hate, r_insult, r_non_toxic,r_obscene, r_severe_toxic, r_threat, r_toxic]\n",
    "avg_log_likelyhood = [b_identity_hate, b_insult, b_non_toxic,b_obscene, b_severe_toxic, b_threat, b_toxic]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([35.710597, 28.647658, 38.363015, 77.651178, ..., 35.791084, 21.364082, 44.33685 , 27.436918]),\n",
       " array([30.70846 , 31.265318, 35.184624, 72.119036, ..., 34.699944, 21.908641, 37.827717, 28.250304]),\n",
       " array([22.853079, 17.742472, 36.114789, 32.825966, ..., 61.718221, 23.333437, 42.910034, 38.362042]),\n",
       " array([31.459666, 28.497778, 33.623783, 71.705547, ..., 38.364751, 22.32773 , 37.504851, 29.099556]),\n",
       " array([30.761464, 32.512364, 32.250011, 84.423839, ..., 31.325096, 21.209258, 40.681086, 22.457835]),\n",
       " array([36.423088, 28.904838, 36.29625 , 67.707815, ..., 38.393286, 28.060976, 48.40332 , 28.037028]),\n",
       " array([34.14729 , 29.516133, 35.735309, 68.836833, ..., 41.11718 , 23.478427, 37.387809, 29.884888])]"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all_val = list(map(lambda x, y: word_doc_valid @ x.T + y, log_likelyhood, avg_log_likelyhood))\n",
    "predictions_all_val"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_index = list(np.argmax(predictions_all_val, 0))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [],
   "source": [
    "prediction_accuracy = np.mean(list(map(lambda x, y : x == y, pred_index, list(toxic_comments.valid_dl.y.items))))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Binarized naive bayes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [],
   "source": [
    "word_doc_binarized = word_doc_train.sign()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "matrix([[0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        ...,\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0],\n",
       "        [0, 0, 1, 0, ..., 0, 0, 0, 0]])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "word_doc_binarized.todense()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_identity_hate_bn, pr_insult_bn, pr_non_toxic_bn,pr_obscene_bn,\\\n",
    "pr_severe_toxic_bn, pr_threat_bn, pr_toxic_bn = [probability(word_doc_binarized, category) for \\\n",
    "                                                            category in [identity_hate, insult, non_toxic,obscene,\\\n",
    "                                                                         severe_toxic, threat, toxic]]  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_identity_hate_bn, r_insult_bn, r_non_toxic_bn,r_obscene_bn,\\\n",
    "r_severe_toxic_bn, r_threat_bn, r_toxic_bn = [np.log(x/np.mean([pr_identity_hate_bn, pr_insult_bn, pr_non_toxic_bn,pr_obscene_bn, pr_severe_toxic_bn, \\\n",
    "                                      pr_threat, pr_toxic])) for x in  [pr_identity_hate_bn, pr_insult_bn, pr_non_toxic_bn, \\\n",
    "                                                                   pr_obscene_bn,  pr_severe_toxic_bn, pr_threat_bn, pr_toxic_bn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_identity_hate_bn, b_insult_bn, b_non_toxic_bn,b_obscene_bn,\\\n",
    "b_severe_toxic_bn, b_threat_bn, b_toxic_bn = [np.log(x.mean()/np.mean(np.mean([pr_identity_hate_bn, pr_insult_bn, pr_non_toxic_bn,pr_obscene_bn, pr_severe_toxic_bn, \\\n",
    "                                      pr_threat_bn, pr_toxic_bn]))) for x in  [pr_identity_hate_bn, pr_insult_bn, pr_non_toxic_bn, \\\n",
    "                                                                   pr_obscene_bn,  pr_severe_toxic_bn, pr_threat_bn, pr_toxic_bn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "go\n",
      "fucking\n",
      "like\n",
      "get\n",
      "wikipedia\n",
      "fuck\n",
      "xxup\n",
      "xxmaj\n",
      "xxbos\n",
      "xxunk\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 51,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_insulting_words_bn = np.argpartition(r_toxic_bn, -10)[-10:]\n",
    "[print(k) for k in [toxic_comments.vocab.itos[i] for i in top_insulting_words_bn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "shit\n",
      "faggot\n",
      "go\n",
      "fucking\n",
      "like\n",
      "gay\n",
      "xxmaj\n",
      "xxup\n",
      "xxbos\n",
      "fuck\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 52,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_identity_hate_words_bn = np.argpartition(r_identity_hate_bn, -10)[-10:]\n",
    "[print(k) for k in [toxic_comments.vocab.itos[i] for i in top_identity_hate_words_bn]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelyhood = [r_identity_hate_bn, r_insult_bn, r_non_toxic_bn,r_obscene_bn, r_severe_toxic_bn, r_threat_bn, r_toxic_bn]\n",
    "avg_log_likelyhood = [b_identity_hate_bn, b_insult_bn, b_non_toxic_bn,b_obscene_bn, b_severe_toxic_bn, b_threat_bn, b_toxic_bn]\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([31.475845, 27.1714  , 39.68173 , 29.59837 , ..., 40.091648, 22.763644, 21.724847, 29.155634]),\n",
       " array([27.039495, 26.966857, 35.182129, 26.887888, ..., 38.517033, 22.649561, 15.308577, 29.599753]),\n",
       " array([26.01916 , 16.895582, 34.903207, 13.687447, ..., 62.754843, 23.89858 , 16.004504, 38.729749]),\n",
       " array([27.687488, 26.63898 , 33.712374, 27.310464, ..., 40.914053, 22.728843, 14.712221, 30.295257]),\n",
       " array([26.087095, 26.701964, 29.844244, 29.726823, ..., 34.358271, 20.743167, 16.339791, 23.454324]),\n",
       " array([33.062303, 28.232593, 38.232978, 28.153114, ..., 42.904236, 26.798872, 27.452647, 29.937506]),\n",
       " array([28.574514, 25.836765, 35.675138, 25.76594 , ..., 43.283309, 24.067169, 14.635176, 30.880935])]"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all_val_bn = list(map(lambda x, y: word_doc_valid.sign() @ x.T + y, log_likelyhood, avg_log_likelyhood))\n",
    "predictions_all_val_bn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.5204205782951559"
      ]
     },
     "execution_count": 55,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_index_bn = list(np.argmax(predictions_all_val_bn, 0))\n",
    "prediction_accuracy_bn = (pred_index_bn == toxic_comments.valid_dl.y.items).mean()\n",
    "prediction_accuracy_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m = LogisticRegression(random_state=0, solver='lbfgs', C = 0.1, multi_class= 'multinomial')\n",
    "m.fit(word_doc_train, toxic_comments.train_dl.y.items.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_log = m.predict(word_doc_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8389936162223056"
      ]
     },
     "execution_count": 58,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_log = (toxic_comments.valid_dl.y.items == pred_log).mean()\n",
    "prediction_accuracy_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Logistic regression- binarized word_doc_matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_bn = LogisticRegression(random_state=0, solver='lbfgs', C = 0.1, multi_class= 'multinomial')\n",
    "m_bn.fit(word_doc_binarized, toxic_comments.train_dl.y.items.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [],
   "source": [
    "pred_bin_log = m_bn.predict(word_doc_valid.sign())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8605182125422456"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "prediction_accuracy_bin_log = (toxic_comments.valid_dl.y.items == pred_bin_log).mean()\n",
    "prediction_accuracy_bin_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "N gram models using CountVectorizer from scikitlearner"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {},
   "outputs": [],
   "source": [
    "count_vcz = CountVectorizer(ngram_range=(1, 3), preprocessor=noop, tokenizer=noop)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [],
   "source": [
    "docs_train = toxic_comments.train_dl.x\n",
    "docs_valid = toxic_comments.valid_dl.x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_words = [[docs_train.vocab.itos[i] for i in doc.data] for doc in docs_train]\n",
    "valid_words = [[docs_valid.vocab.itos[i] for i in doc.data] for doc in docs_valid]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ngram_doc = count_vcz.fit_transform(train_words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "valid_ngram_doc = count_vcz.transform(valid_words)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Naive bayes with ngram word document matrix"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((178498, 6631681), (66575, 6631681))"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_ngram_doc.shape, valid_ngram_doc.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "pr_identity_hate_ngram, pr_insult_ngram, pr_non_toxic_ngram,pr_obscene_ngram,\\\n",
    "pr_severe_toxic_ngram, pr_threat_ngram, pr_toxic_ngram = [probability(train_ngram_doc, category) for \\\n",
    "                                                            category in [identity_hate, insult, non_toxic,obscene,\\\n",
    "                                                                         severe_toxic, threat, toxic]] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {},
   "outputs": [],
   "source": [
    "r_identity_hate_ngram, r_insult_ngram, r_non_toxic_ngram,r_obscene_ngram,\\\n",
    "r_severe_toxic_ngram, r_threat_ngram, r_toxic_ngram = [np.log(x/np.mean([pr_identity_hate_ngram, pr_insult_ngram, pr_non_toxic_ngram,pr_obscene_ngram, pr_severe_toxic_ngram, \\\n",
    "                                      pr_threat_ngram, pr_toxic_ngram])) for x in  [pr_identity_hate_ngram, pr_insult_ngram, pr_non_toxic_ngram, \\\n",
    "                                                                   pr_obscene_ngram,  pr_severe_toxic_ngram, pr_threat_ngram, pr_toxic_ngram]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {},
   "outputs": [],
   "source": [
    "b_identity_hate_ngram, b_insult_ngram, b_non_toxic_ngram,b_obscene_ngram,\\\n",
    "b_severe_toxic_ngram, b_threat_ngram, b_toxic_ngram = [np.log(x.mean()/np.mean(np.mean([pr_identity_hate_ngram, pr_insult_ngram, pr_non_toxic_ngram,pr_obscene_ngram, pr_severe_toxic_ngram, \\\n",
    "                                      pr_threat_ngram, pr_toxic_ngram]))) for x in  [pr_identity_hate_ngram, pr_insult_ngram, pr_non_toxic_ngram, \\\n",
    "                                                                   pr_obscene_ngram,  pr_severe_toxic_ngram, pr_threat_ngram, pr_toxic_ngram]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "u\n",
      "fucking\n",
      "xxbos\n",
      "wikipedia\n",
      "like\n",
      "xxmaj\n",
      "fuck\n",
      "xxup\n",
      "xxunk\n",
      "xxbos xxmaj\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "[None, None, None, None, None, None, None, None, None, None]"
      ]
     },
     "execution_count": 71,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "top_insulting_words_ngram = np.argpartition(r_toxic_ngram, -10)[-10:]\n",
    "[print(k) for k in [count_vcz.get_feature_names()[i] for i in top_insulting_words_ngram]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [],
   "source": [
    "log_likelyhood_ngram = [r_identity_hate_ngram, r_insult_ngram, r_non_toxic_ngram,r_obscene_ngram, r_severe_toxic_ngram, r_threat_ngram, r_toxic_ngram]\n",
    "avg_log_likelyhood_ngram = [b_identity_hate_ngram, b_insult_ngram, b_non_toxic_ngram,b_obscene_ngram, b_severe_toxic_ngram, b_threat_ngram, b_toxic_ngram]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[array([ 54.730974,  49.91606 ,  77.472568, 141.2476  , ...,  67.386026,  32.712261,  70.418311,  41.561865]),\n",
       " array([ 12.251294,  47.035566,  37.975186, 118.252324, ...,  -5.14457 ,  16.435019,  21.647863,  16.338353]),\n",
       " array([-56.931062,  10.761598, -21.908458, -32.770233, ..., -50.012771,   3.663297, -11.947423,   7.245555]),\n",
       " array([ 10.264322,  43.870041,  21.119431, 114.668362, ...,  -4.314838,  17.691604,  20.789914,  16.225503]),\n",
       " array([ 46.569574,  51.324137,  54.049586, 155.816525, ...,  57.612381,  30.926817,  62.297681,  34.313347]),\n",
       " array([ 79.449278,  54.557813,  84.097353, 116.05599 , ..., 118.169225,  50.978835, 102.732784,  59.969331]),\n",
       " array([ 17.91361 ,  40.698917,  24.976848, 103.943857, ..., -24.061947,  14.806187,   7.206227,  10.019007])]"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "predictions_all_val_ngram = list(map(lambda x, y: valid_ngram_doc @ x.T + y, log_likelyhood_ngram, avg_log_likelyhood_ngram))\n",
    "predictions_all_val_ngram"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.03385655276004506"
      ]
     },
     "execution_count": 74,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_index_ngram = list(np.argmax(predictions_all_val_ngram, 0))\n",
    "prediction_accuracy_ngram = (pred_index_ngram == toxic_comments.valid_dl.y.items).mean()\n",
    "prediction_accuracy_ngram"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram with logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 75,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ngram = LogisticRegression(random_state=0, solver='lbfgs', C = 0.1, multi_class= 'multinomial')\n",
    "m_ngram.fit(train_ngram_doc, toxic_comments.train_dl.y.items.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8415471273000376"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_index_ngram_log = m_ngram.predict(valid_ngram_doc)\n",
    "prediction_accuracy_ngram_log = (pred_index_ngram_log == toxic_comments.valid_dl.y.items).mean()\n",
    "prediction_accuracy_ngram_log"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ngram binarized"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/anaconda3/lib/python3.7/site-packages/sklearn/linear_model/logistic.py:758: ConvergenceWarning: lbfgs failed to converge. Increase the number of iterations.\n",
      "  \"of iterations.\", ConvergenceWarning)\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "LogisticRegression(C=0.1, class_weight=None, dual=False, fit_intercept=True,\n",
       "          intercept_scaling=1, max_iter=100, multi_class='multinomial',\n",
       "          n_jobs=None, penalty='l2', random_state=0, solver='lbfgs',\n",
       "          tol=0.0001, verbose=0, warm_start=False)"
      ]
     },
     "execution_count": 77,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m_ngram_bn = LogisticRegression(random_state=0, solver='lbfgs', C = 0.1, multi_class= 'multinomial')\n",
    "m_ngram_bn.fit(train_ngram_doc.sign(), toxic_comments.train_dl.y.items.astype(int))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0.8394442358242583"
      ]
     },
     "execution_count": 78,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pred_index_ngram_log_bn = m_ngram.predict(valid_ngram_doc.sign())\n",
    "prediction_accuracy_ngram_log_bn = (pred_index_ngram_log_bn == toxic_comments.valid_dl.y.items).mean()\n",
    "prediction_accuracy_ngram_log_bn"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Language modelling"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
